{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C4xRCJWhDW1j"
   },
   "source": [
    "# Transformers in NLP\n",
    "\n",
    "Let's start with briefly explaning the Recurrent Network.\n",
    "\n",
    "We mainly use them when dealing with tasks where both the input and outputs are sequences in some defined ordering. Some of the greatest applications of recurrent networks are machine translation and time series data modeling.\n",
    "\n",
    "Let’s consider translating the following French sentence into English. The input transmitted to the encoder is the original French sentence, and the translated output is generated by the decoder.\n",
    "\n",
    "But they are slow!\n",
    "\n",
    "Solution: Transformers\n",
    "\n",
    "- Similar to recurrent networks, transformers also have two main blocs: encoder and decoder, each one having a self-attention mechanism.\n",
    "\n",
    "## Preprocessing:\n",
    "(1) **Embedding of the input data:** the generation of the embeddings of the input sentence (without paying attention to their relationship in the sentence)\n",
    "(2) **Positional encoding:** the computation of the positional vector of each word in the input sentence (The tokenization task discards any notion of relations that existed in the input sentence. The positional encoding tries to create the original cyclic nature by generating a context vector for each word)\n",
    "\n",
    "## Encoder:\n",
    "We get for each word two vectors: (1) the embedding and (2) its context vector. These vectors are added to create a single vector for each word, which is then transmitted to the encoder.\n",
    "\n",
    "(1) **Multi-head attention:** so far, we lost all notion of a relationship. The goal of the attention layer is to capture the contextual relationships existing between different words in the input sentence. This step ends up generating an attention vector for each word.\n",
    "\n",
    "(2) **Position-wise feed-forward net (FFN):** At this stage, a feed-forward neural network is applied to every attention vector to transform them into a format that is expected by the next multi-head attention layer in the decoder.\n",
    "\n",
    "## Decoder:\n",
    "\n",
    "The decoder block consists of three main layers: (1) masked multi-head attention, (2) multi-head attention, and a (3) position-wise feed-forward network. The last two layers are the same in the encoder.\n",
    "\n",
    "The decoder comes into the equation during the training of the network, and it receives two main inputs: (1) the attention vectors of the input sentence we want to translate and (2) the translated target sentences in English.\n",
    "\n",
    "(1)  **masked multi-head attention layer**\n",
    "the network only has to access the previous words. the masked multi-head attention layer masks those next words by transforming them into zeros so that they can’t be used by the attention network.\n",
    "\n",
    "The result of the masked multi-head attention layer passes through the rest of the layers in order to predict the next word by generating a probability score.\n",
    "\n",
    "### Tansfer learning\n",
    "Instead of going through all these challenges, one can re-use pre-trained deep-neural networks as the starting point for training the new model.\n",
    "\n",
    "The re-use of the model involves choosing the pre-trained model that is similar to your use case, refining the input-output pair data of your target task, and retraining the head of the pre-trained model by using your data.\n",
    "\n",
    "\n",
    "## Hugging Face Transformers\n",
    "Hugging Face is an AI community and Machine Learning platform created in 2016 by Julien Chaumond, Clément Delangue, and Thomas Wolf. It aims to democratize NLP by providing Data Scientists, AI practitioners, and Engineers immediate access to over 20,000 pre-trained models based on the state-of-the-art transformer architecture. These models can be applied to\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "executionInfo": {
     "elapsed": 172,
     "status": "ok",
     "timestamp": 1703090417768,
     "user": {
      "displayName": "Burcu Özek",
      "userId": "01642268834999548651"
     },
     "user_tz": 300
    },
    "id": "z0ypt6q8FIXR"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torch\n",
      "  Downloading torch-2.1.2-cp38-none-macosx_10_9_x86_64.whl.metadata (25 kB)\n",
      "Requirement already satisfied: filelock in /Users/burcuozek/opt/anaconda3/envs/burcu/lib/python3.8/site-packages (from torch) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions in /Users/burcuozek/opt/anaconda3/envs/burcu/lib/python3.8/site-packages (from torch) (4.7.1)\n",
      "Collecting sympy (from torch)\n",
      "  Downloading sympy-1.12-py3-none-any.whl (5.7 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.7/5.7 MB\u001b[0m \u001b[31m21.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting networkx (from torch)\n",
      "  Downloading networkx-3.1-py3-none-any.whl (2.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m26.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: jinja2 in /Users/burcuozek/opt/anaconda3/envs/burcu/lib/python3.8/site-packages (from torch) (3.1.2)\n",
      "Requirement already satisfied: fsspec in /Users/burcuozek/opt/anaconda3/envs/burcu/lib/python3.8/site-packages (from torch) (2023.12.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/burcuozek/opt/anaconda3/envs/burcu/lib/python3.8/site-packages (from jinja2->torch) (2.1.1)\n",
      "Collecting mpmath>=0.19 (from sympy->torch)\n",
      "  Downloading mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m536.2/536.2 kB\u001b[0m \u001b[31m21.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading torch-2.1.2-cp38-none-macosx_10_9_x86_64.whl (146.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m146.7/146.7 MB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: mpmath, sympy, networkx, torch\n",
      "Successfully installed mpmath-1.3.0 networkx-3.1 sympy-1.12 torch-2.1.2\n"
     ]
    }
   ],
   "source": [
    "# !pip install transformers sentencepiece\n",
    "# !pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install pandas\n",
    "# !pip install pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install jupyter\n",
    "# !pip install ipykernel\n",
    "# !python -m ipykernel install --user --name=burcuenv --display-name \"My Virtual Environment\"\n",
    "# !jupyter notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "executionInfo": {
     "elapsed": 20,
     "status": "ok",
     "timestamp": 1703090418333,
     "user": {
      "displayName": "Burcu Özek",
      "userId": "01642268834999548651"
     },
     "user_tz": 300
    },
    "id": "WYM4vP3dDW1n"
   },
   "outputs": [],
   "source": [
    "# from transformers import pipeline\n",
    "import pandas as pd\n",
    "from transformers import MarianTokenizer, MarianMTModel\n",
    "import sentencepiece\n",
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6qbdQOH8Dvu6"
   },
   "source": [
    "This dataset is enriched by Facebook and was created to predict the popularity of an article before its publication. The analysis will be based on the description column. To illustrate our examples, we will be using only three examples from the data.\n",
    "\n",
    "Below is a brief description of the data. It has 14 columns and 1428 rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1074,
     "status": "ok",
     "timestamp": 1703090421894,
     "user": {
      "displayName": "Burcu Özek",
      "userId": "01642268834999548651"
     },
     "user_tz": 300
    },
    "id": "ncW4QhQ6DlNq",
    "outputId": "8ae40599-dd7c-4fd3-f155-287800a09e4c"
   },
   "outputs": [],
   "source": [
    "data_path = \"articles_data.csv\"\n",
    "# news_data = pd.read_csv(data_path, error_bad_lines=False)\n",
    "news_data = pd.read_csv(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 970
    },
    "executionInfo": {
     "elapsed": 477,
     "status": "ok",
     "timestamp": 1703090422574,
     "user": {
      "displayName": "Burcu Özek",
      "userId": "01642268834999548651"
     },
     "user_tz": 300
    },
    "id": "rpkWPLa7DlQC",
    "outputId": "3f04c293-b528-4118-ddb1-28eed1e3eb88"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>source_id</th>\n",
       "      <th>source_name</th>\n",
       "      <th>author</th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "      <th>url</th>\n",
       "      <th>url_to_image</th>\n",
       "      <th>published_at</th>\n",
       "      <th>content</th>\n",
       "      <th>top_article</th>\n",
       "      <th>engagement_reaction_count</th>\n",
       "      <th>engagement_comment_count</th>\n",
       "      <th>engagement_share_count</th>\n",
       "      <th>engagement_comment_plugin_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>reuters</td>\n",
       "      <td>Reuters</td>\n",
       "      <td>Reuters Editorial</td>\n",
       "      <td>NTSB says Autopilot engaged in 2018 California...</td>\n",
       "      <td>The National Transportation Safety Board said ...</td>\n",
       "      <td>https://www.reuters.com/article/us-tesla-crash...</td>\n",
       "      <td>https://s4.reutersmedia.net/resources/r/?m=02&amp;...</td>\n",
       "      <td>2019-09-03T16:22:20Z</td>\n",
       "      <td>WASHINGTON (Reuters) - The National Transporta...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2528.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>the-irish-times</td>\n",
       "      <td>The Irish Times</td>\n",
       "      <td>Eoin Burke-Kennedy</td>\n",
       "      <td>Unemployment falls to post-crash low of 5.2%</td>\n",
       "      <td>Latest monthly figures reflect continued growt...</td>\n",
       "      <td>https://www.irishtimes.com/business/economy/un...</td>\n",
       "      <td>https://www.irishtimes.com/image-creator/?id=1...</td>\n",
       "      <td>2019-09-03T10:32:28Z</td>\n",
       "      <td>The States jobless rate fell to 5.2 per cent l...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>the-irish-times</td>\n",
       "      <td>The Irish Times</td>\n",
       "      <td>Deirdre McQuillan</td>\n",
       "      <td>Louise Kennedy AW2019: Long coats, sparkling t...</td>\n",
       "      <td>Autumn-winter collection features designer’s g...</td>\n",
       "      <td>https://www.irishtimes.com/\\t\\t\\t\\t\\t\\t\\t/life...</td>\n",
       "      <td>https://www.irishtimes.com/image-creator/?id=1...</td>\n",
       "      <td>2019-09-03T14:40:00Z</td>\n",
       "      <td>Louise Kennedy is showing off her autumn-winte...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>al-jazeera-english</td>\n",
       "      <td>Al Jazeera English</td>\n",
       "      <td>Al Jazeera</td>\n",
       "      <td>North Korean footballer Han joins Italian gian...</td>\n",
       "      <td>Han is the first North Korean player in the Se...</td>\n",
       "      <td>https://www.aljazeera.com/news/2019/09/north-k...</td>\n",
       "      <td>https://www.aljazeera.com/mritems/Images/2019/...</td>\n",
       "      <td>2019-09-03T17:25:39Z</td>\n",
       "      <td>Han Kwang Song, the first North Korean footbal...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>bbc-news</td>\n",
       "      <td>BBC News</td>\n",
       "      <td>BBC News</td>\n",
       "      <td>UK government lawyer says proroguing parliamen...</td>\n",
       "      <td>The UK government's lawyer, David Johnston arg...</td>\n",
       "      <td>https://www.bbc.co.uk/news/av/uk-scotland-4956...</td>\n",
       "      <td>https://ichef.bbci.co.uk/news/1024/branded_new...</td>\n",
       "      <td>2019-09-03T14:39:21Z</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0           source_id         source_name              author  \\\n",
       "0           0             reuters             Reuters   Reuters Editorial   \n",
       "1           1     the-irish-times     The Irish Times  Eoin Burke-Kennedy   \n",
       "2           2     the-irish-times     The Irish Times   Deirdre McQuillan   \n",
       "3           3  al-jazeera-english  Al Jazeera English          Al Jazeera   \n",
       "4           4            bbc-news            BBC News            BBC News   \n",
       "\n",
       "                                               title  \\\n",
       "0  NTSB says Autopilot engaged in 2018 California...   \n",
       "1       Unemployment falls to post-crash low of 5.2%   \n",
       "2  Louise Kennedy AW2019: Long coats, sparkling t...   \n",
       "3  North Korean footballer Han joins Italian gian...   \n",
       "4  UK government lawyer says proroguing parliamen...   \n",
       "\n",
       "                                         description  \\\n",
       "0  The National Transportation Safety Board said ...   \n",
       "1  Latest monthly figures reflect continued growt...   \n",
       "2  Autumn-winter collection features designer’s g...   \n",
       "3  Han is the first North Korean player in the Se...   \n",
       "4  The UK government's lawyer, David Johnston arg...   \n",
       "\n",
       "                                                 url  \\\n",
       "0  https://www.reuters.com/article/us-tesla-crash...   \n",
       "1  https://www.irishtimes.com/business/economy/un...   \n",
       "2  https://www.irishtimes.com/\\t\\t\\t\\t\\t\\t\\t/life...   \n",
       "3  https://www.aljazeera.com/news/2019/09/north-k...   \n",
       "4  https://www.bbc.co.uk/news/av/uk-scotland-4956...   \n",
       "\n",
       "                                        url_to_image          published_at  \\\n",
       "0  https://s4.reutersmedia.net/resources/r/?m=02&...  2019-09-03T16:22:20Z   \n",
       "1  https://www.irishtimes.com/image-creator/?id=1...  2019-09-03T10:32:28Z   \n",
       "2  https://www.irishtimes.com/image-creator/?id=1...  2019-09-03T14:40:00Z   \n",
       "3  https://www.aljazeera.com/mritems/Images/2019/...  2019-09-03T17:25:39Z   \n",
       "4  https://ichef.bbci.co.uk/news/1024/branded_new...  2019-09-03T14:39:21Z   \n",
       "\n",
       "                                             content  top_article  \\\n",
       "0  WASHINGTON (Reuters) - The National Transporta...          0.0   \n",
       "1  The States jobless rate fell to 5.2 per cent l...          0.0   \n",
       "2  Louise Kennedy is showing off her autumn-winte...          1.0   \n",
       "3  Han Kwang Song, the first North Korean footbal...          0.0   \n",
       "4                                                NaN          0.0   \n",
       "\n",
       "   engagement_reaction_count  engagement_comment_count  \\\n",
       "0                        0.0                       0.0   \n",
       "1                        6.0                      10.0   \n",
       "2                        NaN                       NaN   \n",
       "3                        0.0                       0.0   \n",
       "4                        0.0                       0.0   \n",
       "\n",
       "   engagement_share_count  engagement_comment_plugin_count  \n",
       "0                  2528.0                              0.0  \n",
       "1                     2.0                              0.0  \n",
       "2                     NaN                              NaN  \n",
       "3                     7.0                              0.0  \n",
       "4                     0.0                              0.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10437 entries, 0 to 10436\n",
      "Data columns (total 15 columns):\n",
      " #   Column                           Non-Null Count  Dtype  \n",
      "---  ------                           --------------  -----  \n",
      " 0   Unnamed: 0                       10437 non-null  int64  \n",
      " 1   source_id                        10437 non-null  object \n",
      " 2   source_name                      10437 non-null  object \n",
      " 3   author                           9417 non-null   object \n",
      " 4   title                            10435 non-null  object \n",
      " 5   description                      10413 non-null  object \n",
      " 6   url                              10436 non-null  object \n",
      " 7   url_to_image                     9781 non-null   object \n",
      " 8   published_at                     10436 non-null  object \n",
      " 9   content                          9145 non-null   object \n",
      " 10  top_article                      10435 non-null  float64\n",
      " 11  engagement_reaction_count        10319 non-null  float64\n",
      " 12  engagement_comment_count         10319 non-null  float64\n",
      " 13  engagement_share_count           10319 non-null  float64\n",
      " 14  engagement_comment_plugin_count  10319 non-null  float64\n",
      "dtypes: float64(5), int64(1), object(9)\n",
      "memory usage: 1.2+ MB\n"
     ]
    }
   ],
   "source": [
    "display(news_data.head())\n",
    "# Show data information\n",
    "news_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3jljcXC_E8KF"
   },
   "source": [
    "# Language Translation\n",
    "\n",
    "MariamMT is an efficient Machine Translation framework."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 643
    },
    "executionInfo": {
     "elapsed": 216,
     "status": "error",
     "timestamp": 1703090519343,
     "user": {
      "displayName": "Burcu Özek",
      "userId": "01642268834999548651"
     },
     "user_tz": 300
    },
    "id": "K7qsgpuFDlUp",
    "outputId": "c981e560-84da-48f9-8cdc-bb8a9574b3ac"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/burcuozek/opt/anaconda3/envs/burcu/lib/python3.8/site-packages/transformers/models/marian/tokenization_marian.py:197: UserWarning: Recommended: pip install sacremoses.\n",
      "  warnings.warn(\"Recommended: pip install sacremoses.\")\n"
     ]
    }
   ],
   "source": [
    "# Get the name of the model - english to french\n",
    "from transformers import MarianTokenizer, MarianMTModel\n",
    "model_name = 'Helsinki-NLP/opus-mt-en-fr'\n",
    "\n",
    "# Get the tokenizer\n",
    "tokenizer = MarianTokenizer.from_pretrained(model_name)\n",
    "# Instantiate the model\n",
    "model = MarianMTModel.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "DQ3uMEaMDlWy"
   },
   "outputs": [],
   "source": [
    "def format_batch_texts(language_code, batch_texts):\n",
    "    formated_bach = [\">>{}<< {}\".format(language_code, text) for text in     \n",
    "\n",
    "                batch_texts]\n",
    "    return formated_bach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "pXymtvmmDlZL"
   },
   "outputs": [],
   "source": [
    "def perform_translation(batch_texts, model, tokenizer, language=\"fr\"):\n",
    "\n",
    "    # Prepare the text data into appropriate format for the model\n",
    "    formated_batch_texts = format_batch_texts(language, batch_texts)\n",
    "\n",
    "    # Generate translation using model\n",
    "    translated = model.generate(**tokenizer(formated_batch_texts,\n",
    "\n",
    "                                          return_tensors=\"pt\", padding=True))\n",
    "\n",
    "    # Convert the generated tokens indices back into text\n",
    "    translated_texts = [tokenizer.decode(t, skip_special_tokens=True) for t in translated]\n",
    "\n",
    "    return translated_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Inputs of the model \n",
    "\n",
    "english_texts = [\"Life is good.\", \"Hi everyone?\", \"How are you?\",\"Yay, I did it!\"]\n",
    "# Get the name of the model\n",
    "model_name = 'Helsinki-NLP/opus-mt-en-fr'\n",
    "\n",
    "# Get the tokenizer\n",
    "trans_model_tkn = MarianTokenizer.from_pretrained(model_name)\n",
    "# Instantiate the model\n",
    "trans_model = MarianMTModel.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "id": "1lcs4HBHDlbn"
   },
   "outputs": [],
   "source": [
    "# Check the model translation from the original language (English) to French\n",
    "translated_texts = perform_translation(english_texts, trans_model, trans_model_tkn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "id": "kKJJjlyiDldv"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Life is good.', 'Hi everyone?', 'How are you?', 'Yay, I did it!']\n",
      "Translation : \n",
      " La vie est bonne.\n",
      "Translation : \n",
      " Salut tout le monde?\n",
      "Translation : \n",
      " Comment allez-vous?\n",
      "Translation : \n",
      " Oui, je l'ai fait!\n"
     ]
    }
   ],
   "source": [
    "# Create wrapper to properly format the text\n",
    "from textwrap import TextWrapper\n",
    "# Wrap text to 80 characters.\n",
    "wrapper = TextWrapper(width=80)\n",
    "\n",
    "print(english_texts)\n",
    "for text in translated_texts:\n",
    "    # print(\"Original text: \\n\", text)\n",
    "    print(\"Translation : \\n\", text)\n",
    "    # print(print(wrapper.fill(text)))\n",
    "    # print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "afAbJlZSF7b8"
   },
   "source": [
    "# Zero-shot classification\n",
    "\n",
    "In most cases, the conventional process of training a Machine Learning model requires prior knowledge of all potential labels or targets. For instance, if your initial training labels encompass subjects like science, politics, or education, predicting the label for healthcare would necessitate retraining the model to incorporate that specific label and its associated input data.\n",
    "\n",
    "Contrastingly, there exists an alternative approach that enables the prediction of a text's target without prior exposure to any of the potential labels. This model can be readily utilized by loading it from the hub.\n",
    "\n",
    "The objective here is to categorize the content of previous descriptions, spanning categories such as technology, politics, security, or finance.\n",
    "\n",
    "Yin et al. proposed a method for using pre-trained NLI models as a ready-made zero-shot sequence classifiers. The method works by posing the sequence to be classified as the NLI premise and to construct a hypothesis from each candidate label. For example, if we want to evaluate whether a sequence belongs to the class \"politics\", we could construct a hypothesis of This text is about politics.. The probabilities for entailment and contradiction are then converted to label probabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f6d4aae75d94e13a95f6e2a8f7e708f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.15k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c70c2f492b954bdf9eb6bd9c159a868d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/1.63G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58cb7216432d46908f0b01775b4fe08c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "16fb020ab73340e3972293f16f34c39a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f29118716a145718d7a61d5e5f77f4d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "19f53ca117c942e690e00eaed83a1c2e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "classifier = pipeline(\"zero-shot-classification\",\n",
    "                      model=\"facebook/bart-large-mnli\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "id": "4N1tV2BoF7io"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sequence': 'one day I will see the world',\n",
       " 'labels': ['travel', 'dancing', 'cooking'],\n",
       " 'scores': [0.9938651919364929, 0.0032738035079091787, 0.002861031796783209]}"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequence_to_classify = \"one day I will see the world\"\n",
    "candidate_labels = ['travel', 'cooking', 'dancing']\n",
    "classifier(sequence_to_classify, candidate_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sequence': 'Ankara is the capital of Turkey',\n",
       " 'labels': ['Geography', 'Politics', 'Science'],\n",
       " 'scores': [0.6661186218261719, 0.22976505756378174, 0.1041162982583046]}"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequence_to_classify = \"Ankara is the capital of Turkey\"\n",
    "# we can specify candidate labels in Russian or any other language above:\n",
    "candidate_labels = [\"Politics\", \"Geography\", \"Science\"]\n",
    "classifier(sequence_to_classify, candidate_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X2BHcZe2F6Y6"
   },
   "source": [
    "References:\n",
    "- Dataset: https://www.kaggle.com/datasets/szymonjanowski/internet-articles-data-with-users-engagement\n",
    "- https://www.datacamp.com/tutorial/an-introduction-to-using-transformers-and-hugging-face?utm_source=google&utm_medium=paid_search&utm_campaignid=19589720830&utm_adgroupid=157156377311&utm_device=c&utm_keyword=&utm_matchtype=&utm_network=g&utm_adpostion=&utm_creative=683184495563&utm_targetid=dsa-2218886984100&utm_loc_interest_ms=&utm_loc_physical_ms=9002007&utm_content=&utm_campaign=230119_1-sea~dsa~tofu_2-b2c_3-us_4-prc_5-na_6-na_7-le_8-pdsh-go_9-na_10-na_11-na-dec23&gad_source=1&gclid=CjwKCAiAvoqsBhB9EiwA9XTWGaF9zmUYgdDaR1sVrX6gwZboGV0mzbPkiSedozlj-pvtWmEz6ynCxxoCp3IQAvD_BwE"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
